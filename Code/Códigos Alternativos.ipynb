{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bienestar en Bogotá - OPM\n",
    "## Juan Diego Mayorga \n",
    "## MCPP\n",
    "## 2022-1\n",
    "-------------------\n",
    "## Códigos Alternativos\n",
    "Este código presentará las alternativas que se tuvieron en cuenta para la elaboración del proyecto. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages \n",
    "\n",
    "# OSM\n",
    "#%pip install overpass\n",
    "#%pip install OSMPythonTools]\n",
    "\n",
    "import requests \n",
    "import overpass\n",
    "from OSMPythonTools.overpass import overpassQueryBuilder, Overpass\n",
    "\n",
    "# Data \n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime,timedelta\n",
    "import time\n",
    "\n",
    "# Text \n",
    "import re\n",
    "\n",
    "# Graphs \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Conexión con la API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos conectamos con la API\n",
    "api = overpass.API(endpoint=\"https://overpass.myserver/interpreter\")\n",
    "api = overpass.API(timeout=600)\n",
    "\n",
    "# Dejamos el link abierto para los request \n",
    "op_url = \"https://overpass-api.de/api/interpreter\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Descarga de los datos\n",
    "La API es muy sensible, a continuación un par de errores comunes que encontré \n",
    "\n",
    "1. Tildes: toca escribir tal cual se encuentra la ubicación en OSM\n",
    "2. Palabras extra: por ejemplo, unos querys iniciales que hice tenían escrito \"Localidad Candelaria\", pero en OSM aparece \"Localidad La Candelaria\". Importante tener en cuenta estas variaciones.\n",
    "2. No todas las localidades se escriben o se encuentran de la misma forma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0 Alternativas\n",
    "\n",
    "Esta sección explicaré las alternativas que pude haber escogido para construir el query "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Buffer \n",
    "Siguiendo este post de [Github](https://github.com/nikhilnagargit/OpenStreetMapDataExtraction/blob/master/data_task__by_nikhil.py), la primera aproximación que realicé fue a través de un método de **buffer** en el cual le indicaba a OSM la latitud, longitud y el radio del área que quería analizar y este me arrojaba los resultados. Sin embargo, el principal problema con esta alternativa es que era muy difícil encontrar el centroide de cada una y establecer un radio que no se sobre pusiera a las otras localidades. Por lo tanto, este método quedó descartado después de muchas pruebas. No obstante, recomiendo el código elaborado por @nikhil_nagar porque el trabajo mucho en el output resultado, logra extraer información muy valiosa. \n",
    "\n",
    "##### - Datos totales\n",
    "Como se presenta a continuación, mi segunda aproximación fue hacer un conteo de los datos totales de los amenities que quería estudiar. Esto a través de la sintaxis del código de Overpass, en la cual le pongo al final \"out count;\". Sin embargo, el problema con esta metodología es que OSM no cuenta aquellos establecimientos que no tienen nombre o suficiente información, por lo tanto, tenía un subregistro del número de elementos que estaba buscando. Adicionalmente, esta metodología no me permitía construir mapas de calor dado que solo me arrojaba 19 datos, uno por cada localidad.\n",
    "\n",
    "A continuación presento el código de esta metodología. Esta muy avanzada, incluso logré generar outputs a partir de esta metodología."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Datos totales**\n",
    "\n",
    "En esta sección explicaré como construiré los querys para descargar los datos TOTALES de los amenitys que me interesan de Bogotá por localidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lista de las localidades para hacer un loop \n",
    "# Excluimos Sumapaz \n",
    "localidades = [\"'Localidad Usaquén'\", \"'Localidad Chapinero'\", \"'Localidad Santa Fé'\", \"'Localidad San Cristóbal'\", \"'Localidad Usme'\", \"'Localidad Tunjuelito'\",\n",
    "    \"'Localidad Bosa'\", \"'Localidad Kennedy'\", \"'Localidad Fontibón'\", \"'Localidad Engativá'\", \"'Localidad Suba'\", \"'Localidad Barrios Unidos'\",\n",
    "    \"'Localidad Teusaquillo'\", \"'Localidad Los Mártires'\", \"'Localidad Antonio Nariño'\", \"'Localidad Puente Aranda'\", \"'Localidad La Candelaria'\",\n",
    "    \"'Localidad Rafael Uribe Uribe'\", \"'Localidad Ciudad Bolivar'\"]\n",
    "\n",
    "# Las localidades estan en orden, necesitamos poner un indicador de la zona para lograr un merge con datos administrativos mas adelante\n",
    "# Dado que vamos a hacer pruebas y el len puede que cambie a partir de la lista de localidades, vamos a hacer un comando que tome el tamaño de la lista \n",
    "index_loc = list(range(1,len(localidades)+1))\n",
    "index_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"features\": [{\"geometry\": {\"coordinates\": [-74.085471, 4.604828], \"type\": \"Point\"}, \"id\": 7641780773, \"properties\": {\"name\": \"Localidad Los M\\u00e1rtires\", \"place\": \"suburb\", \"population\": \"99119\", \"wikidata\": \"Q2648349\", \"wikipedia\": \"es:Los M\\u00e1rtires\"}, \"type\": \"Feature\"}], \"type\": \"FeatureCollection\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Primero hagamos unas pruebas \n",
    "\n",
    "# Esta es la estructura básica del lenguaje de programación OSM. Puedo preguntarle por nodos, areas, ways y entre otros. En este caso vamos\n",
    "# A probar ways\n",
    "\n",
    "response = api.get('node[\"name\"=\"Localidad Los Mártires\"]')\n",
    "response\n",
    "# Obtenemos info sobre la localidad los mártiles en bogotá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3216]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agreguemos información adicional a nuestro query como lo puede ser el fomato para exportar las tablas (json), el area donde queremos que busque (e.g Bogotá)\n",
    "# Y el tipo de amenity que queremos encontrar (restaurantes)\n",
    "\n",
    "test = ([])\n",
    "\n",
    "op_query =\"\"\"\n",
    "    [out:json][timeout:25];\n",
    "    area[name='Bogotá']->.search;\n",
    "    node[\"amenity\"=\"restaurant\"](area.search);\n",
    "    out count;out skel qt;\"\"\" # Count se puede cambiar\n",
    "\n",
    "op_query\n",
    "\n",
    "# Aquí utilizamos la función request con su argumento get para realizar el query\n",
    "response = requests.get(op_url, params={\"data\": op_query})\n",
    "\n",
    "# Esta estructura permite transformar los datos de json a data frame\n",
    "x = response.json()\n",
    "data = pd.json_normalize(x[\"elements\"])\n",
    "\n",
    "# Pegamos todos los datos en el vector vacio que construimos arriba\n",
    "test.append(int(data['tags.total'].values[0]))\n",
    "test\n",
    "\n",
    "# Como se puede apreciar, en bogotá hay alrededor de 3212 restaurantes\n",
    "# OJO, estos son restaurantes registrados. En principio hay 6432 pero OSM solo arroja aquellos que tienen info registrada (nombre, ubicación)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código se realizó a partir de la presentación del profesor Nikolai Janakiev \"Data Science with OpenStreetMap and Python (Maptime Salzburg 2018)\"\n",
    "\n",
    "Puede encontrar esta ppt en el siguiente [link](https://www.youtube.com/watch?v=WmCLQCohL3k&t=96s&ab_channel=MaptimeSalzburg]).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora hagamos un loop para cada uno de las localidades. Esto es una prueba para verificar que todas las localidades esten funcionando de forma correcta \n",
    "# Esto es una replicación del código anterior pero aplicado a un loop, esto para que no tengamos que poner cada localidad para un solo amenity\n",
    "\n",
    "restaurantes = []\n",
    "\n",
    "for i in localidades:\n",
    "\n",
    "    p1 = \"\"\"[out:json][timeout:50];\"\"\"\n",
    "    p2 = \"\"\"area[name=\"\"\" + i + \"\"\"]->.search;\"\"\"\n",
    "    p3 =  \"\"\"node[\"amenity\"=\"restaurant\"](area.search);out count;out skel qt;\"\"\"\n",
    "\n",
    "# Tenemos que construir el query por partes porque el loop depende directamente de un str, entonces para incluir las localidades debemos realizar esta modifiación\n",
    "    op_query = p1 + p2 + p3\n",
    "    \n",
    "# Aquí utilizamos la función request con su argumento get para realizar el query\n",
    "    response = requests.get(op_url, params={\"data\": op_query})\n",
    "\n",
    "# Esta estructura permite transformar los datos de json a data frame\n",
    "    x = response.json()\n",
    "\n",
    "# Pegamos todos los datos en el vector vacio que construimos arriba\n",
    "    data = pd.json_normalize(x[\"elements\"])\n",
    "    restaurantes.append(int(data['tags.total'].values[0]))\n",
    "\n",
    "# La API no permite hacer cierto numero de querys al tiempo, por tanto, toca poner a dormir al código para que no identifique nuestras multiples solicitudes    \n",
    "    time.sleep(8)\n",
    "\n",
    "# Guardamos todo en un df\n",
    "# Le agregamos un identificador de la localidad y su nombre\n",
    "rest = pd.DataFrame(\n",
    "    {\"Restaurantes\": restaurantes, \"Localidad\": index_loc, \"Nom_localidad\": localidades})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora generaré una función que permita descargar cualquier tipo de dato en relación a amenity's \n",
    "\n",
    "def get_amenity(amenity):\n",
    "\n",
    "    '''\n",
    "    La siguiente función le permite al usaurio descargar diferentes amenitys para distintas areas del mundo. \n",
    "    El único argumento es el nombre del amenity. \n",
    "    Si lo desea, puede ajustar las localidades, esto creando una lista con dichas ubicaciones. \n",
    "    Para saber que tipo de información se puede seleccionar por favor revise el siguiente link: https://wiki.openstreetmap.org/wiki/Key:amenity\n",
    "    '''\n",
    "\n",
    "    y = []\n",
    "    for i in localidades:\n",
    "        \n",
    "# Dado que debemos meterle una parte en código al str en lenguase OSM debemos hacer la siguiente opreación \n",
    "        p1 = \"\"\"[out:json][timeout:50];\"\"\"\n",
    "        p2 = \"\"\"area[name=\"\"\" + i + \"\"\"]->.search;\"\"\"\n",
    "        p3 =  \"\"\"node[\"amenity\"=\"\"\" + amenity + \"\"\"](area.search);out count;\"\"\"\n",
    "\n",
    "        op_query = p1 + p2 + p3\n",
    "        \n",
    "        response = requests.get(op_url, params={\"data\": op_query})\n",
    "        x = response.json()\n",
    "        data = pd.json_normalize(x[\"elements\"])\n",
    "        y.append(int(data['tags.total'].values[0]))\n",
    "\n",
    "# La API no permite hacer cierto numero de querys al tiempo, por tanto, toca poner a dormir al código para que no nos saque \n",
    "# Este puede ir cambiando, dado que vamos a hacer multiples request, puede que arroje errores a la hora de calcularlo \n",
    "        time.sleep(5)\n",
    "    data_id = pd.DataFrame(\n",
    "    {amenity: y, \"Localidad\": index_loc, \"Nom_localidad\": localidades})\n",
    "\n",
    "    return data_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba para saber si la función es correcta \n",
    "restaurantes = get_amenity(\"restaurant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "**Creación de las bases de datos** \n",
    "\n",
    "Vamos a hacer por grupos de interés las bases de datos y posteriormente se unirán todas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entretenimiento, Arte y Cultura**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base de datos de los ameneity que corresponden a entrenimineto, arte y cultura \n",
    "casino = get_amenity(\"casino\")\n",
    "cinema = get_amenity(\"cinema\")\n",
    "community_centre = get_amenity(\"community_centre\")\n",
    "love_hotel = get_amenity(\"love_hotel\")\n",
    "nightclub = get_amenity(\"nightclub\")\n",
    "theatre = get_amenity(\"theatre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos la base de datos de entretenimiento\n",
    "entre = pd.concat([cinema, community_centre, love_hotel, nightclub, theatre], axis=1)\n",
    "\n",
    "# Eliminamos los duplicados \n",
    "entre = entre.loc[:,~entre.columns.duplicated()]\n",
    "\n",
    "# Creamos una variable que sume el total de amenitys \n",
    "entre[\"Total Entretenimiento\"] = entre[\"cinema\"] + entre[\"community_centre\"] + entre[\"love_hotel\"] + entre[\"nightclub\"] + entre[\"theatre\"]\n",
    "\n",
    "entre.to_csv(\"Data sets/Entretenimiento.csv\", sep = \";\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comida**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = get_amenity(\"bar\")\n",
    "pub = get_amenity(\"pub\")\n",
    "cafe = get_amenity(\"cafe\")\n",
    "fast_food = get_amenity(\"fast_food\")\n",
    "restaurant = get_amenity(\"restaurant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos la base de datos de comida\n",
    "comida = pd.concat([bar, pub, cafe, fast_food, restaurant], axis=1)\n",
    "comida = comida.loc[:,~comida.columns.duplicated()]\n",
    "\n",
    "# Creamos una variable que sume el total de amenitys \n",
    "comida[\"Total Comida\"] = comida[\"bar\"] + comida[\"pub\"] + comida[\"cafe\"] + comida[\"fast_food\"] + comida[\"restaurant\"] \n",
    "\n",
    "comida.to_csv(\"Data sets/Comida.csv\", sep = \";\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Education**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_1 = get_amenity(\"college\")\n",
    "uni_2 = get_amenity(\"university\")\n",
    "pre_school = get_amenity(\"kindergarten\")\n",
    "colegio = get_amenity(\"school\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos la base de datos de educación \n",
    "edu = pd.concat([uni_1, uni_2, pre_school, colegio], axis=1)\n",
    "edu = edu.loc[:,~edu.columns.duplicated()]\n",
    "\n",
    "# Creamos una variable que sume el total de amenitys \n",
    "# Para educación crearemos dos variables, una con superior y otra primaria/secundaria\n",
    "edu[\"Primaria\"] = edu[\"kindergarten\"] + edu[\"school\"]\n",
    "edu[\"Superior\"] = edu[\"college\"] + edu[\"university\"]\n",
    "\n",
    "edu.to_csv(\"Data sets/Educación.csv\", sep = \";\", index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "efb17e5bfbf4581ee388028022334b1903202e979e18a00399327c90fdf4addf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
